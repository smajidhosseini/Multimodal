{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-25 19:30:02.173534: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-25 19:30:02.998892: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib64:\n",
      "2023-08-25 19:30:02.998981: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib64:\n",
      "2023-08-25 19:30:02.998992: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import warnings, os\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.layers import Input, Conv1D, Conv2D, MaxPooling1D, MaxPooling2D, Flatten, concatenate, Dense\n",
    "from keras.models import Model\n",
    "from tensorflow.keras.layers import Concatenate\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Concatenate, Flatten, Dense, Reshape\n",
    "from keras.models import Model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D,MaxPool1D, Flatten, Dense, Dropout\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.layers.pooling import MaxPooling2D, MaxPool1D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import data\n",
    "path = '/nfsmount/majid/StressDetection/Hypothesis/Morteza/backup/Final'\n",
    "bio_file = 'Lasso_features_bio.csv'\n",
    "land_file = 'Lasso_features_land.csv'\n",
    "bio_label_file = 'data_scaled.individually_bio4.csv'\n",
    "land_label_file = 'data_scaled.individually_landmark4.csv'\n",
    "#import data\n",
    "bio_data = pd.read_csv(os.path.join(path,bio_file)).dropna(axis=0)\n",
    "land_data = pd.read_csv(os.path.join(path,land_file)).dropna(axis=0)\n",
    "bio_label = pd.read_csv(os.path.join(path,bio_label_file)).dropna(axis=0)\n",
    "land_label = pd.read_csv(os.path.join(path,land_label_file)).dropna(axis=0)\n",
    "#extract  labels and user IDs from another file\n",
    "bio_label = bio_label[['user','label']]\n",
    "land_label = land_label[['user','label']]\n",
    "\n",
    "bio_data = bio_data.join(bio_label)\n",
    "land_data = land_data.join(land_label)\n",
    "#Save the files for later runs\n",
    "#bio_data.to_csv('fetured_bio.csv',index=False)\n",
    "#land_data.to_csv('fetured_land.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index(['avg_TEMP', 'min_TEMP', 'energy_TEMP', 'quantile_TEMP', 'RMS_TEMP',\n",
       "        'min_SCR_Height', 'std_EDA_Tonic', 'std_EDA_Phasic', 'max_EDA_Phasic',\n",
       "        'min_EDA_Phasic', 'energy_EDA_Phasic', 'quantile_EDA_Phasic',\n",
       "        'RMS_EDA_Phasic', 'variance_EDA_Phasic', 'avg_EDA_Clean',\n",
       "        'std_EDA_Clean', 'max_EDA_Clean', 'energy_EDA_Clean', 'RMS_EDA_Clean',\n",
       "        'max_HR', 'energy_HR', 'avg_EDA', 'max_EDA', 'energy_EDA',\n",
       "        'quantile_EDA', 'RMS_EDA', 'variance_EDA', 'EDA_Tonic', 'EDA_Phasic',\n",
       "        'TEMP', 'user', 'label'],\n",
       "       dtype='object'),\n",
       " (39257, 32),\n",
       " Index(['max_X1', 'min_X1', 'energy_X1', 'variation_X1', 'energy_X5',\n",
       "        'variance_X5', 'std_X3', 'energy_X3', 'max_X2', 'energy_X4',\n",
       "        ...\n",
       "        'min_Y53', 'avg_Y57', 'max_Y57', 'RMS_Y57', 'std_Y56', 'variation_Y67',\n",
       "        'max_Y65', 'variation_Y65', 'user', 'label'],\n",
       "       dtype='object', length=102),\n",
       " (39257, 102))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#investigate data shapes to avoid mismatchs \n",
    "bio_data.columns ,bio_data.shape, land_data.columns ,land_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "height = 10  # Height of your signal data (number of time steps)\n",
    "width = 10   # Width of your signal data (number of features)\n",
    "channels = 1 # Number of channels (e.g., 1 for grayscale)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Model.png](Model.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 30)]         0           []                               \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 30, 1)        0           ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 10, 10, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 28, 32)       128         ['reshape[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 8, 8, 32)     320         ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " max_pooling1d (MaxPooling1D)   (None, 14, 32)       0           ['conv1d[0][0]']                 \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 4, 4, 32)     0           ['conv2d[0][0]']                 \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 448)          0           ['max_pooling1d[0][0]']          \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)            (None, 512)          0           ['max_pooling2d[0][0]']          \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 50)           22450       ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 50)           25650       ['flatten_1[0][0]']              \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 25)           1275        ['dense[0][0]']                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 25)           1275        ['dense_3[0][0]']                \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-25 19:30:19.728091: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib64:\n",
      "2023-08-25 19:30:19.728158: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-08-25 19:30:19.728563: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 3)            78          ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 0)            0           ['dense_4[0][0]']                \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 3)            0           ['dense_2[0][0]',                \n",
      "                                                                  'dense_5[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 51,176\n",
      "Trainable params: 51,176\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#define the multimodal late fusion model using keras\n",
    "input_bio = Input(shape=(30,))\n",
    "input_land = Input(shape=(height, width, channels))\n",
    "x_bio = Reshape((30, 1))(input_bio)\n",
    "x_bio = Conv1D(filters=32, kernel_size=3, activation='relu')(x_bio)\n",
    "x_bio = MaxPool1D(pool_size=2)(x_bio)\n",
    "x_bio = Flatten()(x_bio)\n",
    "x_bio = Dense(50, activation='relu')(x_bio)\n",
    "x_bio = Dense(25, activation='relu')(x_bio)\n",
    "output_bio = Dense(3, activation='softmax')(x_bio)\n",
    "x_land = Conv2D(32, kernel_size=(3, 3), activation='relu')(input_land)\n",
    "x_land = MaxPooling2D(pool_size=(2, 2))(x_land)\n",
    "x_land = Flatten()(x_land)\n",
    "x_land = Dense(50, activation='relu')(x_land)\n",
    "x_land = Dense(25, activation='relu')(x_land)\n",
    "output_land = Dense(0, activation='softmax')(x_land)\n",
    "\n",
    "# Concatenate the two output layers\n",
    "concatenated_output = Concatenate()([output_bio, output_land])\n",
    "# Create the late fusion model\n",
    "late_fusion_model = Model(inputs=[input_bio, input_land], outputs=concatenated_output)\n",
    "\n",
    "# Compile the model\n",
    "late_fusion_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print model summary\n",
    "late_fusion_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "late_fusion_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H\n",
      "Epoch 1/10\n",
      "4491/4491 [==============================] - 13s 3ms/step - loss: 0.3893 - accuracy: 0.8472\n",
      "Epoch 2/10\n",
      "4491/4491 [==============================] - 12s 3ms/step - loss: 0.1806 - accuracy: 0.9282\n",
      "Epoch 3/10\n",
      "4491/4491 [==============================] - 12s 3ms/step - loss: 0.1342 - accuracy: 0.9459\n",
      "Epoch 4/10\n",
      "4491/4491 [==============================] - 12s 3ms/step - loss: 0.1113 - accuracy: 0.9540\n",
      "Epoch 5/10\n",
      "4491/4491 [==============================] - 11s 2ms/step - loss: 0.0994 - accuracy: 0.9591\n",
      "Epoch 6/10\n",
      "4491/4491 [==============================] - 11s 2ms/step - loss: 0.0867 - accuracy: 0.9639\n",
      "Epoch 7/10\n",
      "4491/4491 [==============================] - 12s 3ms/step - loss: 0.0819 - accuracy: 0.9669\n",
      "Epoch 8/10\n",
      "4491/4491 [==============================] - 11s 3ms/step - loss: 0.0731 - accuracy: 0.9700\n",
      "Epoch 9/10\n",
      "4491/4491 [==============================] - 11s 3ms/step - loss: 0.0690 - accuracy: 0.9727\n",
      "Epoch 10/10\n",
      "4491/4491 [==============================] - 11s 2ms/step - loss: 0.0626 - accuracy: 0.9756\n",
      "I\n",
      "Epoch 1/10\n",
      "4415/4415 [==============================] - 11s 3ms/step - loss: 0.0607 - accuracy: 0.9769\n",
      "Epoch 2/10\n",
      "4415/4415 [==============================] - 12s 3ms/step - loss: 0.0543 - accuracy: 0.9796\n",
      "Epoch 3/10\n",
      "4415/4415 [==============================] - 12s 3ms/step - loss: 0.0516 - accuracy: 0.9796\n",
      "Epoch 4/10\n",
      "4415/4415 [==============================] - 11s 3ms/step - loss: 0.0496 - accuracy: 0.9810\n",
      "Epoch 5/10\n",
      "4415/4415 [==============================] - 11s 3ms/step - loss: 0.0446 - accuracy: 0.9823\n",
      "Epoch 6/10\n",
      "4415/4415 [==============================] - 10s 2ms/step - loss: 0.0403 - accuracy: 0.9841\n",
      "Epoch 7/10\n",
      "4415/4415 [==============================] - 11s 2ms/step - loss: 0.0416 - accuracy: 0.9847\n",
      "Epoch 8/10\n",
      "4415/4415 [==============================] - 10s 2ms/step - loss: 0.0392 - accuracy: 0.9849\n",
      "Epoch 9/10\n",
      "4415/4415 [==============================] - 11s 2ms/step - loss: 0.0380 - accuracy: 0.9856\n",
      "Epoch 10/10\n",
      "4415/4415 [==============================] - 11s 2ms/step - loss: 0.0363 - accuracy: 0.9864\n",
      "J\n",
      "Epoch 1/10\n",
      "4439/4439 [==============================] - 11s 2ms/step - loss: 0.0457 - accuracy: 0.9841\n",
      "Epoch 2/10\n",
      "4439/4439 [==============================] - 11s 3ms/step - loss: 0.0359 - accuracy: 0.9861\n",
      "Epoch 3/10\n",
      "4439/4439 [==============================] - 11s 2ms/step - loss: 0.0314 - accuracy: 0.9886\n",
      "Epoch 4/10\n",
      "4439/4439 [==============================] - 10s 2ms/step - loss: 0.0325 - accuracy: 0.9877\n",
      "Epoch 5/10\n",
      "4439/4439 [==============================] - 11s 2ms/step - loss: 0.0302 - accuracy: 0.9886\n",
      "Epoch 6/10\n",
      "4439/4439 [==============================] - 11s 2ms/step - loss: 0.0311 - accuracy: 0.9883\n",
      "Epoch 7/10\n",
      "4439/4439 [==============================] - 11s 2ms/step - loss: 0.0287 - accuracy: 0.9888\n",
      "Epoch 8/10\n",
      "4439/4439 [==============================] - 11s 2ms/step - loss: 0.0278 - accuracy: 0.9892\n",
      "Epoch 9/10\n",
      "4439/4439 [==============================] - 11s 2ms/step - loss: 0.0275 - accuracy: 0.9894\n",
      "Epoch 10/10\n",
      " 197/4439 [>.............................] - ETA: 11s - loss: 0.0294 - accuracy: 0.9879"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/nfsmount/majid/StressDetection/Hypothesis/Majid/Latefusion_keras concatenate.ipynb Cell 7\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22444e34227d/nfsmount/majid/StressDetection/Hypothesis/Majid/Latefusion_keras%20concatenate.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=37'>38</a>\u001b[0m y_train \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mto_categorical(ytrain_bio, num_classes\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22444e34227d/nfsmount/majid/StressDetection/Hypothesis/Majid/Latefusion_keras%20concatenate.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=38'>39</a>\u001b[0m y_test \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mto_categorical(ytest_bio, num_classes\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22444e34227d/nfsmount/majid/StressDetection/Hypothesis/Majid/Latefusion_keras%20concatenate.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=39'>40</a>\u001b[0m late_fusion_model\u001b[39m.\u001b[39;49mfit([Xtrain_bio, Xtrain_land], y_train, epochs\u001b[39m=\u001b[39;49mepochs, batch_size\u001b[39m=\u001b[39;49m\u001b[39m8\u001b[39;49m, verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n",
      "File \u001b[0;32m~/anaconda3/envs/TSP/lib/python3.9/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/TSP/lib/python3.9/site-packages/keras/engine/training.py:1650\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1642\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1643\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1644\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   1648\u001b[0m ):\n\u001b[1;32m   1649\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1650\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1651\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1652\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/anaconda3/envs/TSP/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/TSP/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:880\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    877\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    879\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 880\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    882\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    883\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/anaconda3/envs/TSP/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:912\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    909\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    910\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    911\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 912\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_no_variable_creation_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    913\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    914\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    915\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    916\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/anaconda3/envs/TSP/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:133\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[39m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    132\u001b[0m   (concrete_function,\n\u001b[0;32m--> 133\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_maybe_define_function(args, kwargs)\n\u001b[1;32m    134\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39m_call_flat(\n\u001b[1;32m    135\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39mconcrete_function\u001b[39m.\u001b[39mcaptured_inputs)\n",
      "File \u001b[0;32m~/anaconda3/envs/TSP/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:336\u001b[0m, in \u001b[0;36mTracingCompiler._maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m    331\u001b[0m captures \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_captures_container\u001b[39m.\u001b[39mget_snapshot()\n\u001b[1;32m    333\u001b[0m \u001b[39m# cache_key_deletion_observer is useless here. It's based on all captures.\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[39m# A new cache key will be built later when saving ConcreteFunction because\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \u001b[39m# only active captures should be saved.\u001b[39;00m\n\u001b[0;32m--> 336\u001b[0m lookup_func_key, _ \u001b[39m=\u001b[39m function_context\u001b[39m.\u001b[39;49mmake_cache_key((args, kwargs),\n\u001b[1;32m    337\u001b[0m                                                      captures)\n\u001b[1;32m    338\u001b[0m concrete_function \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function_cache\u001b[39m.\u001b[39mlookup(lookup_func_key, \u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    339\u001b[0m \u001b[39mif\u001b[39;00m concrete_function \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/TSP/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/function_context.py:133\u001b[0m, in \u001b[0;36mmake_cache_key\u001b[0;34m(args, captures)\u001b[0m\n\u001b[1;32m    131\u001b[0m   captures \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m()\n\u001b[1;32m    132\u001b[0m signature_context \u001b[39m=\u001b[39m trace_type\u001b[39m.\u001b[39mInternalTracingContext()\n\u001b[0;32m--> 133\u001b[0m args_signature \u001b[39m=\u001b[39m trace_type\u001b[39m.\u001b[39;49mfrom_value(\n\u001b[1;32m    134\u001b[0m     args, signature_context)\n\u001b[1;32m    135\u001b[0m captures_dict_tracetype \u001b[39m=\u001b[39m trace_type\u001b[39m.\u001b[39mfrom_value(\n\u001b[1;32m    136\u001b[0m     captures, signature_context)\n\u001b[1;32m    138\u001b[0m \u001b[39m# TODO(fmuham): Use the actual FunctionType\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/TSP/lib/python3.9/site-packages/tensorflow/core/function/trace_type/trace_type_builder.py:129\u001b[0m, in \u001b[0;36mfrom_value\u001b[0;34m(value, context)\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[39mreturn\u001b[39;00m default_types\u001b[39m.\u001b[39mNamedTuple\u001b[39m.\u001b[39mfrom_type_and_attributes(\n\u001b[1;32m    127\u001b[0m         named_tuple_type, \u001b[39mtuple\u001b[39m(from_value(c, context) \u001b[39mfor\u001b[39;00m c \u001b[39min\u001b[39;00m value))\n\u001b[1;32m    128\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 129\u001b[0m     \u001b[39mreturn\u001b[39;00m default_types\u001b[39m.\u001b[39;49mTuple(\u001b[39m*\u001b[39;49m(from_value(c, context) \u001b[39mfor\u001b[39;49;00m c \u001b[39min\u001b[39;49;00m value))\n\u001b[1;32m    131\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(value, collections\u001b[39m.\u001b[39mabc\u001b[39m.\u001b[39mMapping):\n\u001b[1;32m    132\u001b[0m   \u001b[39mreturn\u001b[39;00m default_types\u001b[39m.\u001b[39mDict({k: from_value(value[k], context) \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m value})\n",
      "File \u001b[0;32m~/anaconda3/envs/TSP/lib/python3.9/site-packages/tensorflow/core/function/trace_type/trace_type_builder.py:129\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[39mreturn\u001b[39;00m default_types\u001b[39m.\u001b[39mNamedTuple\u001b[39m.\u001b[39mfrom_type_and_attributes(\n\u001b[1;32m    127\u001b[0m         named_tuple_type, \u001b[39mtuple\u001b[39m(from_value(c, context) \u001b[39mfor\u001b[39;00m c \u001b[39min\u001b[39;00m value))\n\u001b[1;32m    128\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 129\u001b[0m     \u001b[39mreturn\u001b[39;00m default_types\u001b[39m.\u001b[39mTuple(\u001b[39m*\u001b[39m(from_value(c, context) \u001b[39mfor\u001b[39;00m c \u001b[39min\u001b[39;00m value))\n\u001b[1;32m    131\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(value, collections\u001b[39m.\u001b[39mabc\u001b[39m.\u001b[39mMapping):\n\u001b[1;32m    132\u001b[0m   \u001b[39mreturn\u001b[39;00m default_types\u001b[39m.\u001b[39mDict({k: from_value(value[k], context) \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m value})\n",
      "File \u001b[0;32m~/anaconda3/envs/TSP/lib/python3.9/site-packages/tensorflow/core/function/trace_type/trace_type_builder.py:114\u001b[0m, in \u001b[0;36mfrom_value\u001b[0;34m(value, context)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[39mif\u001b[39;00m context\u001b[39m.\u001b[39mis_legacy_signature \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(value, trace\u001b[39m.\u001b[39mTraceType):\n\u001b[1;32m    113\u001b[0m   \u001b[39mreturn\u001b[39;00m value\n\u001b[0;32m--> 114\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39;49m(value, trace\u001b[39m.\u001b[39;49mSupportsTracingProtocol):\n\u001b[1;32m    115\u001b[0m   \u001b[39mreturn\u001b[39;00m value\u001b[39m.\u001b[39m__tf_tracing_type__(context)\n\u001b[1;32m    117\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(value, \u001b[39m\"\u001b[39m\u001b[39m__wrapped__\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[0;32m~/anaconda3/envs/TSP/lib/python3.9/typing.py:1145\u001b[0m, in \u001b[0;36m_ProtocolMeta.__instancecheck__\u001b[0;34m(cls, instance)\u001b[0m\n\u001b[1;32m   1141\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__instancecheck__\u001b[39m(\u001b[39mcls\u001b[39m, instance):\n\u001b[1;32m   1142\u001b[0m     \u001b[39m# We need this method for situations where attributes are\u001b[39;00m\n\u001b[1;32m   1143\u001b[0m     \u001b[39m# assigned in __init__.\u001b[39;00m\n\u001b[1;32m   1144\u001b[0m     \u001b[39mif\u001b[39;00m ((\u001b[39mnot\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mcls\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m_is_protocol\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m) \u001b[39mor\u001b[39;00m\n\u001b[0;32m-> 1145\u001b[0m             _is_callable_members_only(\u001b[39mcls\u001b[39;49m)) \u001b[39mand\u001b[39;00m\n\u001b[1;32m   1146\u001b[0m             \u001b[39missubclass\u001b[39m(instance\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m, \u001b[39mcls\u001b[39m)):\n\u001b[1;32m   1147\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m   1148\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_is_protocol:\n",
      "File \u001b[0;32m~/anaconda3/envs/TSP/lib/python3.9/typing.py:1084\u001b[0m, in \u001b[0;36m_is_callable_members_only\u001b[0;34m(cls)\u001b[0m\n\u001b[1;32m   1082\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_is_callable_members_only\u001b[39m(\u001b[39mcls\u001b[39m):\n\u001b[1;32m   1083\u001b[0m     \u001b[39m# PEP 544 prohibits using issubclass() with protocols that have non-method members.\u001b[39;00m\n\u001b[0;32m-> 1084\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mall\u001b[39m(callable(\u001b[39mgetattr\u001b[39m(\u001b[39mcls\u001b[39m, attr, \u001b[39mNone\u001b[39;00m)) \u001b[39mfor\u001b[39;00m attr \u001b[39min\u001b[39;00m _get_protocol_attrs(\u001b[39mcls\u001b[39;49m))\n",
      "File \u001b[0;32m~/anaconda3/envs/TSP/lib/python3.9/typing.py:1077\u001b[0m, in \u001b[0;36m_get_protocol_attrs\u001b[0;34m(cls)\u001b[0m\n\u001b[1;32m   1075\u001b[0m     annotations \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(base, \u001b[39m'\u001b[39m\u001b[39m__annotations__\u001b[39m\u001b[39m'\u001b[39m, {})\n\u001b[1;32m   1076\u001b[0m     \u001b[39mfor\u001b[39;00m attr \u001b[39min\u001b[39;00m \u001b[39mlist\u001b[39m(base\u001b[39m.\u001b[39m\u001b[39m__dict__\u001b[39m\u001b[39m.\u001b[39mkeys()) \u001b[39m+\u001b[39m \u001b[39mlist\u001b[39m(annotations\u001b[39m.\u001b[39mkeys()):\n\u001b[0;32m-> 1077\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m attr\u001b[39m.\u001b[39;49mstartswith(\u001b[39m'\u001b[39;49m\u001b[39m_abc_\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mand\u001b[39;00m attr \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m EXCLUDED_ATTRIBUTES:\n\u001b[1;32m   1078\u001b[0m             attrs\u001b[39m.\u001b[39madd(attr)\n\u001b[1;32m   1079\u001b[0m \u001b[39mreturn\u001b[39;00m attrs\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#leave one out cross validation using user ids from H to R\n",
    "epochs = 10\n",
    "\n",
    "for user in bio_data.user.unique():\n",
    "    print(user)\n",
    "    #Leave One subject Out Cross Validation train test split\n",
    "    train_bio, train_land = bio_data[bio_data['user']!=user], land_data[land_data['user']!=user]\n",
    "    test_bio,  test_land  = bio_data[bio_data['user']==user], land_data[land_data['user']==user]\n",
    "\n",
    "    #split labels and features\n",
    "    Xtrain_bio, Xtest_bio = train_bio.drop(columns=['user','label']), test_bio.drop(columns=['user','label'])\n",
    "    ytrain_bio, ytest_bio = train_bio['label'], test_bio['label']\n",
    "\n",
    "    \n",
    "    Xtrain_land = train_land.drop(columns=['user','label'])\n",
    "    #reshape training facial landmark data for conv2d\n",
    "    Xtrain_land = np.reshape(Xtrain_land.iloc[:, :100].values, (Xtrain_land.shape[0], height, width, channels))\n",
    "\n",
    "    ytrain_land = train_land['label'].values.astype(int)\n",
    "    encoder = LabelEncoder()\n",
    "    ytrain_land = encoder.fit_transform(ytrain_land)\n",
    "\n",
    "    Xtest_land = test_land.drop(columns=['user','label'])\n",
    "    Xtest_land = np.reshape(Xtest_land.iloc[:, :100].values, (Xtest_land.shape[0], height, width, channels))\n",
    "    \n",
    "    ytest_land = test_land['label']\n",
    "    ytest_land = ytest_land.values.astype(int)\n",
    "    encoder = LabelEncoder()\n",
    "    ytest_land = encoder.fit_transform(ytest_land)\n",
    "\n",
    "    #test station for debugging purposes\n",
    "    #print('Xtrain_bio.shape',Xtrain_bio.shape, 'ytrain_bio.shape',ytrain_bio.shape, 'Xtest_bio.shape',Xtest_bio.shape, 'ytest_bio.shape',ytest_bio.shape)\n",
    "    #print('Xtrain_land.shape',Xtrain_land.shape, 'ytrain_land.shape',ytrain_land.shape, 'Xtest_land.shape',Xtest_land.shape, 'ytest_land.shape',ytest_land.shape)\n",
    "\n",
    "    y_train = tf.keras.utils.to_categorical(ytrain_bio, num_classes=3)\n",
    "    y_test = tf.keras.utils.to_categorical(ytest_bio, num_classes=3)\n",
    "    late_fusion_model.fit([Xtrain_bio, Xtrain_land], y_train, epochs=epochs, batch_size=8, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118/118 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[9.9999994e-01, 0.0000000e+00, 0.0000000e+00],\n",
       "       [9.9999994e-01, 0.0000000e+00, 0.0000000e+00],\n",
       "       [9.9999994e-01, 0.0000000e+00, 0.0000000e+00],\n",
       "       ...,\n",
       "       [9.9999994e-01, 1.1746341e-16, 1.0339516e-19],\n",
       "       [9.9999994e-01, 1.2245754e-16, 8.3240225e-20],\n",
       "       [9.9999994e-01, 1.2252062e-16, 6.3550399e-20]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predict \n",
    "y_pred = late_fusion_model.predict([Xtest_bio, Xtest_land])\n",
    "y_pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TSP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
